# ðŸ§  IntelGenie - Multi-Agent Research Assistant

IntelGenie is a LangGraph + LLaMA-powered research assistant that automates research, summarization, and strategic recommendations into a downloadable `.docx` report â€” all running locally.

## ðŸš€ Features
- Multi-agent pipeline: Research â†’ Summarize â†’ Recommend
- Uses Ollama's LLaMA 3 â€” no API key needed
- Outputs clean Word reports with cover page
- Smart LLM-generated report filenames

## ðŸ› ï¸ Technologies
- [LangGraph](https://github.com/langchain-ai/langgraph)
- [LangChain](https://github.com/langchain-ai/langchain)
- [Streamlit](https://streamlit.io)
- [Ollama](https://ollama.com/)
- Python 3.10+

## ðŸ“¦ Installation

```bash
git clone https://github.com/Chetansonawane7/-IntelGenie---Multi-Agent-Research-Assistant.git
cd IntelGenie
pip install -r requirements.txt
```

Start Ollama if not running
```bash
Ollama run llama3
```

Start the App:
```bash
streamlit run app.py
```

ðŸ“ Example Output
Query	Filename
"How does AI impact healthcare?"	AI_in_Healthcare_IntelGenie_Report.docx

ðŸ“„ License
MIT

ðŸ‘¤ Built by Your Name

yaml
Copy
Edit

---

### ðŸ“¦ 2. `requirements.txt`

Use this as a base:

streamlit
langchain
langgraph
langchain-community
langchain-core
python-dotenv
duckduckgo-search
pypdf
faiss-cpu
sentence-transformers
python-docx

go
Copy
Edit

Add:
```bash
pip freeze > requirements.txt
```
Then remove your local-only or version-specific junk lines.


ðŸ”’ 3. .env.example
env
Copy
Edit
# If you ever use OpenAI or HuggingFace
OPENAI_API_KEY=your_key_here
